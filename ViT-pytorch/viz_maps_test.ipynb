{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VisionTransformer, CONFIGS\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbaselines\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mViT\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mViT_explanation_generator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LRP\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from models.modeling import VisionTransformer, CONFIGS\n",
    "from baselines.ViT.ViT_explanation_generator import LRP\n",
    "\n",
    "# Load the model\n",
    "config = CONFIGS[\"ViT-B_16\"]\n",
    "model = VisionTransformer(config, num_classes=24, zero_head=False, img_size=224, vis=True)\n",
    "checkpoint = torch.load(\"output/test_checkpoint.pth\")  # Load the checkpoint\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Load the image\n",
    "im = Image.open(\"augmented_data_test/img8504_flip_rescale_augmented.jpg\")\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "# Transform the image\n",
    "x = transform(im).unsqueeze(0)\n",
    "\n",
    "# Generate attention maps for each keypoint\n",
    "attribution_generator = LRP(model)\n",
    "keypoint_attention_maps = []\n",
    "\n",
    "for i in range(12):\n",
    "    # Generate attention map for each keypoint\n",
    "    transformer_attribution = attribution_generator.generate_LRP(x, method=\"transformer_attribution\", index=i).detach()\n",
    "    transformer_attribution = transformer_attribution.reshape(1, 1, 14, 14)\n",
    "    transformer_attribution = F.interpolate(transformer_attribution, scale_factor=16, mode='bilinear')\n",
    "    transformer_attribution = transformer_attribution.reshape(224, 224).data.numpy()\n",
    "    transformer_attribution = (transformer_attribution - transformer_attribution.min()) / (transformer_attribution.max() - transformer_attribution.min())\n",
    "    keypoint_attention_maps.append(transformer_attribution)\n",
    "\n",
    "# Plot the attention maps for each keypoint\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.set_title(f\"Keypoint {i+1}\")\n",
    "    ax.imshow(im)\n",
    "    ax.imshow(keypoint_attention_maps[i], alpha=0.7, cmap='hot')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
