{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform\n",
    "import math\n",
    "from skimage.transform import rotate\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "        self.name = 'rescale'\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "\n",
    "        # h and w are swapped for landmarks because for images,\n",
    "        # x and y axes are axis 1 and 0 respectively\n",
    "        landmarks = landmarks * [new_w / w, new_h / h]\n",
    "        return {'image': img, 'landmarks': landmarks}\n",
    "\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "        self.name = 'crop'\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h + 1)\n",
    "        left = np.random.randint(0, w - new_w + 1)\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        landmarks = landmarks - [left, top]\n",
    "\n",
    "        return {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'landmarks': torch.from_numpy(landmarks)}\n",
    "\n",
    "class ZeroPadHeight(object):\n",
    "    \"\"\"Pad the height of the image with zeros to a given height.\"\"\"\n",
    "\n",
    "    def __init__(self, output_height):\n",
    "        self.output_height = output_height\n",
    "        self.name = 'ZeroPad'\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h = self.output_height\n",
    "\n",
    "        pad_height = max(0, new_h - h)\n",
    "        top_padding = pad_height // 2\n",
    "        bottom_padding = pad_height - top_padding\n",
    "\n",
    "        image = np.pad(image, ((top_padding, bottom_padding), (0, 0), (0, 0)), mode='constant')\n",
    "\n",
    "        landmarks = landmarks + [0, top_padding]  # Adjust landmarks for the top padding\n",
    "\n",
    "        return {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "class Rotate(object):\n",
    "    \"\"\"Rotate image and landmarks by a given angle.\"\"\"\n",
    "    \n",
    "    def __init__(self, angle):\n",
    "        self.angle = angle\n",
    "        self.name = 'rotate'\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        h, w = image.shape[:2]\n",
    "        center = (w / 2, h / 2)\n",
    "        \n",
    "        # Rotate the image\n",
    "        rotated_image = rotate(image, self.angle, resize=False, center=center, order=1, mode='constant', cval=0, clip=True, preserve_range=False)\n",
    "        \n",
    "        # Rotate the landmarks\n",
    "        theta = math.radians(-self.angle)  # Convert angle from degrees to radians\n",
    "        cos_angle = math.cos(theta)\n",
    "        sin_angle = math.sin(theta)\n",
    "        \n",
    "        rotated_landmarks = np.empty_like(landmarks)\n",
    "        for i, (x, y) in enumerate(landmarks):\n",
    "            x_rotated = (x - center[0]) * cos_angle - (y - center[1]) * sin_angle + center[0]\n",
    "            y_rotated = (x - center[0]) * sin_angle + (y - center[1]) * cos_angle + center[1]\n",
    "            rotated_landmarks[i] = [x_rotated, y_rotated]\n",
    "        \n",
    "        return {'image': rotated_image, 'landmarks': rotated_landmarks}\n",
    "\n",
    "\n",
    "class GaussianBlur(object):\n",
    "    \"\"\"Apply Gaussian Blur to the image in the sample.\"\"\"\n",
    "\n",
    "    def __init__(self, sigma=2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sigma (float): Standard deviation for Gaussian kernel. The higher the value, the more blur.\n",
    "        \"\"\"\n",
    "        self.sigma = sigma\n",
    "        self.name = 'blur'\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']\n",
    "        blurred_image = gaussian_filter(image, sigma=self.sigma)\n",
    "\n",
    "        return {'image': blurred_image, 'landmarks': landmarks}\n",
    "\n",
    "class HorizontalFlip(object):\n",
    "    \"\"\"Flip image and landmarks horizontally.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = 'flip'\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, landmarks = sample['image'], sample['landmarks']        \n",
    "        flipped_image = np.fliplr(image)\n",
    "        image_width = image.shape[1]\n",
    "        flipped_landmarks = np.copy(landmarks)\n",
    "        flipped_landmarks[:, 0] = image_width - landmarks[:, 0]\n",
    "        \n",
    "        return {'image': flipped_image, 'landmarks': flipped_landmarks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, utils\n",
    "\n",
    "rotate_rescale = transforms.Compose([\n",
    "    Rotate(20),\n",
    "    ZeroPadHeight(846),\n",
    "    Rescale(224)\n",
    "])\n",
    "\n",
    "flip_rescale = transforms.Compose([\n",
    "    HorizontalFlip(),\n",
    "    ZeroPadHeight(846),\n",
    "    Rescale(224)\n",
    "])\n",
    "\n",
    "pad_rescale = transforms.Compose([\n",
    "    ZeroPadHeight(846),  # Set the desired height \n",
    "    Rescale(224),\n",
    "])\n",
    "\n",
    "rotate_flip_rescale = transforms.Compose([\n",
    "    HorizontalFlip(),\n",
    "    Rotate(20),\n",
    "    ZeroPadHeight(846),\n",
    "    Rescale(224)\n",
    "])\n",
    "\n",
    "blur = transforms.Compose([\n",
    "    GaussianBlur(),\n",
    "    ZeroPadHeight(846),\n",
    "    Rescale(224)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "\n",
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "class AugmentedFaceDataset:\n",
    "    \"\"\"Dataset class for loading, augmenting, and saving face images and their labels.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, output_dir, output_size=(846, 646), transform=None):\n",
    "        # Read the first two rows after the header to use as new headers\n",
    "        initial_df = pd.read_csv(csv_file, nrows=2, skiprows=[0], header=None)\n",
    "        new_headers = ['image_name'] + [f\"{initial_df.iloc[0, i]}_{initial_df.iloc[1, i]}\" for i in range(3, len(initial_df.columns))]\n",
    "        \n",
    "        # Now read the CSV with the appropriate rows and columns using the new headers\n",
    "        self.face_frame = pd.read_csv(\n",
    "            csv_file,\n",
    "            skiprows=[1, 2],  # Skip the first two rows after the header\n",
    "            usecols=list(range(2, len(initial_df.columns))),  # Use columns from the third onwards\n",
    "            names=new_headers,  # Set the new header names\n",
    "            header=0  # Use the original header to ignore it in processing\n",
    "        )\n",
    "        \n",
    "        self.root_dir = root_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.output_size = output_size\n",
    "        self.transform = transform\n",
    "        self._prepare_output_directory()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.face_frame)\n",
    "\n",
    "    def apply_transforms_and_save(self, transforms_list):\n",
    "        \"\"\"Apply a list of transforms individually and save the augmented data.\"\"\"\n",
    "        test_dict = {\n",
    "            rotate_rescale: 'rotate_rescale',\n",
    "            flip_rescale: 'flip_rescale',\n",
    "            pad_rescale: 'pad_rescale',\n",
    "            rotate_flip_rescale: 'rotate_flip_rescale',\n",
    "            blur: 'blur'\n",
    "        }\n",
    "        d_augmented_labels_all = pd.DataFrame()\n",
    "        for idx in range(len(self)):\n",
    "            sample = self.__getitem__(idx, apply_transform=False)  # Get original sample\n",
    "\n",
    "            for tsfrm in transforms_list:\n",
    "                # Apply transform\n",
    "                transformed_sample = tsfrm(sample)\n",
    "                # Save augmented data\n",
    "                d_augmented_labels = self._save_augmented_data(idx, transformed_sample, test_dict[tsfrm])\n",
    "                d_augmented_labels_all = pd.concat([d_augmented_labels_all, d_augmented_labels])\n",
    "        \n",
    "        # Ensure the output directory exists\n",
    "        output_dir = self.output_dir\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        # Save the consolidated CSV file\n",
    "        d_augmented_labels_all.set_index('image_name').to_csv(os.path.join(output_dir, 'augmented_labels.csv'))\n",
    "\n",
    "    def __getitem__(self, idx, apply_transform=True):\n",
    "        img_name = os.path.join(self.root_dir, self.face_frame.iloc[idx, 0])  # Example image name\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.face_frame.iloc[idx, 1:].values.reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform and apply_transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def _prepare_output_directory(self):\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def _save_augmented_data(self, idx, sample, transform_name):\n",
    "        # Extract the original name directly from the first column of the CSV.\n",
    "        original_file_name = self.face_frame.iloc[idx, 0]\n",
    "\n",
    "        # Generate the new filenames for the augmented image and CSV by appending the transform name\n",
    "        file_name_without_extension, file_extension = os.path.splitext(original_file_name)\n",
    "    \n",
    "        augmented_image_filename = f\"{file_name_without_extension}_{transform_name}_augmented.jpg\"\n",
    "    \n",
    "        # Full path for the augmented image\n",
    "        augmented_image_path = os.path.join(self.output_dir, augmented_image_filename)\n",
    "    \n",
    "        # Save the augmented image. Ensure the image data is in the correct format (e.g., scale to 255 if necessary).\n",
    "        io.imsave(augmented_image_path, (sample['image'] * 255).astype(np.uint8))\n",
    "    \n",
    "        # Prepare the DataFrame for augmented labels\n",
    "        d_augmented_labels = pd.DataFrame(flatten(sample['landmarks'])[0:24]).transpose()\n",
    "        d_augmented_labels.columns = self.face_frame.columns[1:25].to_list()\n",
    "        d_augmented_labels['image_name'] = augmented_image_filename\n",
    "\n",
    "        # Return the augmented labels to be added to the main DataFrame\n",
    "        return d_augmented_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/annastuckert/Documents/GitHub/ViT_facemap/ViT-pytorch\"\n",
    "csv_file = f\"{root}/data/facemap/data_No_NaN/train/train_data.csv\"\n",
    "source_folder = f\"{root}/data/facemap/data_No_NaN/train/\"\n",
    "output_dir = f\"{root}/data/facemap/data_No_NaN/train/augmented_data\"\n",
    "\n",
    "# Example usage\n",
    "transforms_list = [rotate_rescale, flip_rescale, pad_rescale, rotate_flip_rescale, blur]\n",
    "face_dataset = AugmentedFaceDataset(csv_file=\"/Users/annastuckert/Documents/GitHub/ViT_facemap/ViT-pytorch/data/facemap/data_No_NaN/train/train_data.csv\", root_dir=source_folder, output_dir=output_dir)\n",
    "#face_dataset = AugmentedFaceDataset(csv_file='data/facemap/LabeledData/Test/CollectedDataTest.csv', root_dir='data/facemap/LabeledData/Test/', output_dir='augmented_data_test/')\n",
    "face_dataset.apply_transforms_and_save(transforms_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
