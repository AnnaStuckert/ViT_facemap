{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annastuckert/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1352: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor size: torch.Size([1, 197, 768])\n"
     ]
    }
   ],
   "source": [
    "import einops\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "import cv2\n",
    "\n",
    "from models.modeling import VisionTransformer, CONFIGS\n",
    "from vit_grad_rollout import VITAttentionGradRollout\n",
    "config = CONFIGS[\"ViT-B_16\"]\n",
    "model = VisionTransformer(config, num_classes=24, zero_head=False, img_size=224, vis=True)\n",
    "#checkpoint = torch.load(\"output/test_checkpoint.pth\", map_location=torch.device('cpu'))  # Load the checkpoint # remove map_location=torch.device('cpu') if running on GPU\n",
    "image = Image.open(\"augmented_data_test/img8504_flip_rescale_augmented.jpg\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    #transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "x = transform(image)\n",
    "\n",
    "grad_rollout = VITAttentionGradRollout(model, discard_ratio=0.9) #deleted head_fusion='max'\n",
    "mask = grad_rollout(x.unsqueeze(0), category_index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
