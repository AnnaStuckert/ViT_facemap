{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution notebook\n",
    "This notebook serves as a walk-through of the code to execute training of the ViT keypoint tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.train_test_split import test_train_split\n",
    "import utils.data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare paths\n",
    "\n",
    "root = \"/Users/annastuckert/Documents/GitHub/ViT_facemap/ViT-pytorch\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "### Test-train split (incl. dropping NAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid image name: nan\n",
      "Invalid image name: nan\n",
      "Invalid image name: nan\n",
      "Invalid image name: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           scorer   Unnamed: 1   Unnamed: 2                AVS  \\\n",
       " 3    labeled-data  cam1_G7c1_1  img0068.png  589.0232336327339   \n",
       " 43   labeled-data  cam1_G7c1_1  img2997.png  590.5093017792906   \n",
       " 48   labeled-data  cam1_G7c1_1  img3575.png  589.0232336327339   \n",
       " 68   labeled-data  cam1_G7c1_1  img5379.png  581.5928928999506   \n",
       " 79   labeled-data  cam1_G7c1_1  img6392.png  586.0510973396206   \n",
       " 89   labeled-data  cam1_G7c1_1  img7197.png  583.0789610465073   \n",
       " 105  labeled-data  cam1_G7c1_1  img8629.png  587.5371654861773   \n",
       " \n",
       "                  AVS.1               AVS.2               AVS.3  \\\n",
       " 3    67.63932048311811  502.83128113244777  106.27709229359114   \n",
       " 43   67.63932048311811  507.28948557211777  106.27709229359114   \n",
       " 48   64.66718419000479  507.28948557211777  101.81888785392117   \n",
       " 68   64.66718419000479   498.3730766927779  122.62384190571437   \n",
       " 79   67.63932048311811  507.28948557211777  109.24922858670446   \n",
       " 89   67.63932048311811   504.3173492790045  104.79102414703449   \n",
       " 105  64.66718419000479   508.7755537186745  112.22136487981778   \n",
       " \n",
       "                  AVS.4               AVS.5              AVS.6  ...  \\\n",
       " 3    562.2740069947141   173.1501588886407  636.5774143225469  ...   \n",
       " 43   566.7322114343841  171.66409074208406  633.6052780294336  ...   \n",
       " 48   568.2182795809407   174.6362270351974  636.5774143225469  ...   \n",
       " 68   574.1625521671674   174.6362270351974  638.0634824691036  ...   \n",
       " 79   574.1625521671674   171.6640907420841  635.0913461759903  ...   \n",
       " 89   566.7322114343841  167.20588630241411  636.5774143225469  ...   \n",
       " 105   571.190415874054  171.66409074208406  633.6052780294336  ...   \n",
       " \n",
       "                  AVS.14              AVS.15              AVS.16  \\\n",
       " 3    369.08514794234867  242.99536177680352   355.7105346233388   \n",
       " 43    370.5712160889053  242.99536177680346   361.6548072095654   \n",
       " 48    397.3204427269252  238.53715733713358  348.28019389055544   \n",
       " 68    378.0015568216886  237.05108919057687  339.36378501121555   \n",
       " 79    366.1130116492354   250.4257025095868  349.76626203711214   \n",
       " 89    345.3080575974422  190.98297664732053  334.90558057154556   \n",
       " 105  297.75387690762915  232.59288475090688   325.9891716922056   \n",
       " \n",
       "                  AVS.17              AVS.18              AVS.19  \\\n",
       " 3     295.0077469062865  300.72601320074244   391.6021764324692   \n",
       " 43   196.92724923354717   311.1284902266391  385.65790384624256   \n",
       " 48   185.03870406109388  305.18421764041244   387.1439719927992   \n",
       " 68    286.0913380269466  305.18421764041244   391.6021764324692   \n",
       " 79   189.49690850076388   337.8777168646589  284.60526988038987   \n",
       " 89    280.1470654407199  315.58669466630903   390.1161082859125   \n",
       " 105  195.44118108699047   311.1284902266391  393.08824457902585   \n",
       " \n",
       "                  AVS.20              AVS.21 AVS.22 AVS.23  \n",
       " 3     348.2801938905555  428.75388009638567    NaN    NaN  \n",
       " 43   357.19660276989543   421.3235393636023    NaN    NaN  \n",
       " 48    345.3080575974422  413.89319863081903    NaN    NaN  \n",
       " 68    343.8219894508855    418.351403070489    NaN    NaN  \n",
       " 79                  NaN                 NaN    NaN    NaN  \n",
       " 89    343.8219894508855  413.89319863081903    NaN    NaN  \n",
       " 105  342.33592130432885   419.8374712170457    NaN    NaN  \n",
       " \n",
       " [7 rows x 27 columns],\n",
       " '/Users/annastuckert/Documents/GitHub/ViT_facemap/ViT-pytorch/data/facemap/data_No_NaN/train/train_data.csv',\n",
       " '/Users/annastuckert/Documents/GitHub/ViT_facemap/ViT-pytorch/data/facemap/data_No_NaN/test/test_data.csv')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define paths\n",
    "csv_path = f\"{root}/data/facemap/CollectedData_AVS.csv\"\n",
    "dest_folder = f\"{root}/data/facemap/data_No_NaN\"\n",
    "source_folder = f\"{root}/data/facemap\"\n",
    "\n",
    "\n",
    "# Call the function to process data\n",
    "test_train_split(csv_path, source_folder, dest_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Rotate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms, utils\n\u001b[0;32m----> 3\u001b[0m rotate_rescale \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([Rotate(\u001b[38;5;241m20\u001b[39m), ZeroPadHeight(\u001b[38;5;241m846\u001b[39m), Rescale(\u001b[38;5;241m224\u001b[39m)])\n\u001b[1;32m      5\u001b[0m flip_rescale \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([HorizontalFlip(), ZeroPadHeight(\u001b[38;5;241m846\u001b[39m), Rescale(\u001b[38;5;241m224\u001b[39m)])\n\u001b[1;32m      7\u001b[0m pad_rescale \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose(\n\u001b[1;32m      8\u001b[0m     [\n\u001b[1;32m      9\u001b[0m         ZeroPadHeight(\u001b[38;5;241m846\u001b[39m),  \u001b[38;5;66;03m# Set the desired height\u001b[39;00m\n\u001b[1;32m     10\u001b[0m         Rescale(\u001b[38;5;241m224\u001b[39m),\n\u001b[1;32m     11\u001b[0m     ]\n\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Rotate' is not defined"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, utils\n",
    "\n",
    "rotate_rescale = transforms.Compose([Rotate(20), ZeroPadHeight(846), Rescale(224)])\n",
    "\n",
    "flip_rescale = transforms.Compose([HorizontalFlip(), ZeroPadHeight(846), Rescale(224)])\n",
    "\n",
    "pad_rescale = transforms.Compose(\n",
    "    [\n",
    "        ZeroPadHeight(846),  # Set the desired height\n",
    "        Rescale(224),\n",
    "    ]\n",
    ")\n",
    "\n",
    "rotate_flip_rescale = transforms.Compose(\n",
    "    [HorizontalFlip(), Rotate(20), ZeroPadHeight(846), Rescale(224)]\n",
    ")\n",
    "\n",
    "blur = transforms.Compose([GaussianBlur(), ZeroPadHeight(846), Rescale(224)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rotate_rescale' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m transforms_list \u001b[38;5;241m=\u001b[39m [rotate_rescale, flip_rescale, pad_rescale, rotate_flip_rescale, blur]\n\u001b[1;32m      3\u001b[0m face_dataset \u001b[38;5;241m=\u001b[39m AugmentedFaceDataset(\n\u001b[1;32m      4\u001b[0m     csv_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;132;01m{dest_folder}\u001b[39;00m\u001b[38;5;124m/train/train_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     root_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;132;01m{dest_folder}\u001b[39;00m\u001b[38;5;124m/train/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;132;01m{dest_folder}\u001b[39;00m\u001b[38;5;124m/train/augmented_data/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# face_dataset = AugmentedFaceDataset(csv_file='data/facemap/LabeledData/Test/CollectedDataTest.csv', root_dir='data/facemap/LabeledData/Test/', output_dir='augmented_data_test/')\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rotate_rescale' is not defined"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "transforms_list = [rotate_rescale, flip_rescale, pad_rescale, rotate_flip_rescale, blur]\n",
    "face_dataset = AugmentedFaceDataset(\n",
    "    csv_file=\"f{dest_folder}/train/train_data.csv\",\n",
    "    root_dir=\"f{dest_folder}/train/\",\n",
    "    output_dir=\"f{dest_folder}/train/augmented_data/\",\n",
    ")\n",
    "# face_dataset = AugmentedFaceDataset(csv_file='data/facemap/LabeledData/Test/CollectedDataTest.csv', root_dir='data/facemap/LabeledData/Test/', output_dir='augmented_data_test/')\n",
    "face_dataset.apply_transforms_and_save(transforms_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Training\n",
    "\n",
    "In order to train the ViT, the following sections are run. Subprocess is used in order to run train.py from within a python script.\n",
    "\n",
    "For reference, the following arguments are to be specified for the training model.\n",
    "\n",
    "\"--name\", default=\"test\" \n",
    "--> \"Name of this run. Used for monitoring.\"\n",
    "\n",
    "\"--dataset\", default=\"facemap\" \n",
    "--> \"Which downstream task and dataset to use\"\n",
    "\n",
    "\"--model_type\", choices=[\"ViT-B_16\", \"ViT-B_32\", \"ViT-L_16\", \"ViT-L_32\", \"ViT-H_14\", \"R50-ViT-B_16\"], default=\"ViT-B_16\"\n",
    "-->help=\"Which variant to use.\"\n",
    "\n",
    "\"--pretrained_dir\", type=str, default=\"ViT-B_16.npz\"\n",
    "--> \"Where to search for pretrained ViT models. If not modified, will search in the directory where .ipynb project execution file is placed.\"\n",
    "\n",
    "\"--output_dir\", default=\"output\", type=str\n",
    "-->\"The output directory where checkpoints will be written.\"\n",
    "\n",
    "\"--img_size\", default=224, type=int\n",
    "--> =\"Resolution size for image\"\n",
    "\n",
    "\"--train_batch_size\", default=20, type=int\n",
    "--> \"Batch size for training.\"\n",
    "\n",
    "\"--eval_batch_size\", default=20, type=int\n",
    "h--> \"Total batch size for eval.\"\n",
    "\n",
    "\"--eval_every\", default=100, type=int,\n",
    "--> \"Run prediction on validation set every so many steps. Will always run one evaluation at the end of training.\"\n",
    "\n",
    "\"--learning_rate\", default=2e-4, type=float,\n",
    "--> \"The initial learning rate for the optimizer.\"\n",
    "\n",
    "\"--weight_decay\", default=1e-2, type=float,\n",
    "--> \"Weight deay if we apply some.\"\n",
    "\n",
    "\"--num_steps\", default=3000, type=int,\n",
    "--> \"Total number of training epochs to perform.\"\n",
    "\n",
    "\"--decay_type\", choices=[\"cosine\", \"linear\"], default=\"linear\", #changed from cosine as I believe this is what Yichen did\n",
    "--> \"How to decay the learning rate.\"\n",
    "\n",
    "\"--warmup_steps\", default=500, type=int,\n",
    "--> \"Step of training to perform learning rate warmup for.\"\n",
    "\n",
    "\"--max_grad_norm\", default=1.0, type=float,\n",
    "--> \"Max gradient norm.\"\n",
    "\n",
    "\"--local_rank\", type=int, default=-1,\n",
    "--> \"local_rank for distributed training on gpus\" - I think this might be if you have more than one GPU available, you can distribute training. Or if one GPU has more than one core\n",
    "\n",
    "'--seed', type=int, default=42,\n",
    "--> \"random seed for initialization\"\n",
    "\n",
    "'--gradient_accumulation_steps', type=int, default=1, # tried adjusting this from 1 to 25 to match Yichen\n",
    "--> \"Number of updates steps to accumulate before performing a backward/update pass.\"\n",
    "\n",
    "('--fp16', action='store_true',\n",
    "--> \"Whether to use 16-bit float precision instead of 32-bit\")\n",
    "\n",
    "'--fp16_opt_level', type=str, default='O2',\n",
    "-->\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"\n",
    "                             \"See details at https://nvidia.github.io/apex/amp.html\")\n",
    "\n",
    "'--loss_scale', type=float, default=0,\n",
    "-->\"Loss scaling to improve fp16 numeric stability. Only used when fp16 set to True. 0 (default value): dynamic loss scaling. Positive power of 2: static loss scaling value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: load_pretrained: grid-size from 24 to 14\n",
      "85.817112\n",
      "Input tensor size: torch.Size([20, 197, 768])\n",
      "Input tensor size: torch.Size([20, 197, 768])\n",
      "Input tensor size: torch.Size([20, 197, 768])\n",
      "Input tensor size: torch.Size([20, 197, 768])\n",
      "Input tensor size: torch.Size([20, 197, 768])\n",
      "Input tensor size: torch.Size([20, 197, 768])\n",
      "Input tensor size: torch.Size([20, 197, 768])\n",
      "Input tensor size: torch.Size([20, 197, 768])\n",
      "Input tensor size: torch.Size([20, 197, 768])\n",
      "Input tensor size: torch.Size([20, 197, 768])\n",
      "Input tensor size: torch.Size([20, 197, 768])\n",
      "Input tensor size: torch.Size([20, 197, 768])\n",
      "Data: {'steps': [0, 1, 2, 3, 4, 5, 5], 'metric': ['training_loss', 'training_loss', 'training_loss', 'training_loss', 'training_loss', 'validation_loss', 'validation_acc'], 'training_loss': [10727.318359375, 10490.2548828125, 10947.5283203125, 10596.41015625, 11004.0400390625, 10698.757358871764, 0.0], 'validation_loss': [None, None, None, None, None, None, None], 'validation_acc': [None, None, None, None, None, None, None]}\n",
      "Metric: training_loss, Indices: [0, 1, 2, 3, 4]\n",
      "Steps: [0, 1, 2, 3, 4], Loss: [10727.318359375, 10490.2548828125, 10947.5283203125, 10596.41015625, 11004.0400390625]\n",
      "Metric: validation_loss, Indices: [5]\n",
      "Steps: [5], Loss: [None]\n",
      "Metric: validation_acc, Indices: [6]\n",
      "Steps: [5], Loss: [None]\n",
      "Figure(640x480)\n",
      "\n",
      "Errors: 08/18/2024 18:59:22 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "08/18/2024 18:59:23 - INFO - models.modeling - load_pretrained: resized variant: torch.Size([1, 577, 768]) to torch.Size([1, 197, 768])\n",
      "08/18/2024 18:59:23 - INFO - __main__ - classifier: token\n",
      "hidden_size: 768\n",
      "patches:\n",
      "  size: !!python/tuple\n",
      "  - 16\n",
      "  - 16\n",
      "representation_size: null\n",
      "transformer:\n",
      "  attention_dropout_rate: 0.0\n",
      "  dropout_rate: 0.1\n",
      "  mlp_dim: 3072\n",
      "  num_heads: 12\n",
      "  num_layers: 12\n",
      "\n",
      "08/18/2024 18:59:23 - INFO - __main__ - Training parameters Namespace(name='experiment_20240813', dataset='facemap', model_type='ViT-B_16', pretrained_dir='ViT-B_16.npz', output_dir='model_checkpoints', img_size=224, train_batch_size=20, eval_batch_size=20, eval_every=5, learning_rate=0.0002, weight_decay=0.01, num_steps=5, decay_type='linear', warmup_steps=1, max_grad_norm=1.0, local_rank=-1, seed=42, gradient_accumulation_steps=1, fp16=False, fp16_opt_level='O2', loss_scale=0, root_directory='.', n_gpu=0, device=device(type='cpu'))\n",
      "08/18/2024 18:59:23 - INFO - __main__ - Total Parameter: \t85.8M\n",
      "08/18/2024 18:59:23 - INFO - __main__ - ***** Running training *****\n",
      "08/18/2024 18:59:23 - INFO - __main__ -   Total optimization steps = 5\n",
      "08/18/2024 18:59:23 - INFO - __main__ -   Instantaneous batch size per GPU = 20\n",
      "08/18/2024 18:59:23 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 20\n",
      "08/18/2024 18:59:23 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "\n",
      "Training (0 / 5 Steps) (loss=0):   0%|| 0/50 [00:00<?, ?it/s]/Users/annastuckert/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "\n",
      "Training (1 / 5 Steps) (loss=10727.31836):   0%|| 0/50 [00:24<?, ?it/s]/Users/annastuckert/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:271: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "\n",
      "Training (1 / 5 Steps) (loss=10727.31836):   2%|| 1/50 [00:24<19:46, 24.22s/it]\n",
      "Training (2 / 5 Steps) (loss=10490.25488):   2%|| 1/50 [00:31<19:46, 24.22s/it]\n",
      "Training (2 / 5 Steps) (loss=10490.25488):   4%|| 2/50 [00:31<11:28, 14.35s/it]\n",
      "Training (3 / 5 Steps) (loss=10947.52832):   4%|| 2/50 [00:45<11:28, 14.35s/it]\n",
      "Training (3 / 5 Steps) (loss=10947.52832):   6%|| 3/50 [00:45<11:03, 14.12s/it]\n",
      "Training (4 / 5 Steps) (loss=10596.41016):   6%|| 3/50 [00:55<11:03, 14.12s/it]\n",
      "Training (4 / 5 Steps) (loss=10596.41016):   8%|| 4/50 [00:55<09:42, 12.66s/it]\n",
      "Training (5 / 5 Steps) (loss=11004.04004):   8%|| 4/50 [01:06<09:42, 12.66s/it]08/18/2024 19:00:30 - INFO - __main__ - ***** Running Validation *****\n",
      "08/18/2024 19:00:30 - INFO - __main__ -   Num steps = 7\n",
      "08/18/2024 19:00:30 - INFO - __main__ -   Batch size = 20\n",
      "\n",
      "\n",
      "Validating... (loss=X.X):   0%|| 0/7 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Validating... (loss=10752.53196):   0%|| 0/7 [00:09<?, ?it/s]\u001b[A\n",
      "\n",
      "Validating... (loss=10752.53196):  14%|| 1/7 [00:09<00:59,  9.94s/it]\u001b[A\n",
      "\n",
      "Validating... (loss=10749.73102):  14%|| 1/7 [00:11<00:59,  9.94s/it]\u001b[A\n",
      "\n",
      "Validating... (loss=10749.73102):  29%|| 2/7 [00:11<00:26,  5.29s/it]\u001b[A\n",
      "\n",
      "Validating... (loss=10667.27624):  29%|| 2/7 [00:13<00:26,  5.29s/it]\u001b[A\n",
      "\n",
      "Validating... (loss=10667.27624):  43%|| 3/7 [00:13<00:14,  3.69s/it]\u001b[A\n",
      "\n",
      "Validating... (loss=10736.27822):  43%|| 3/7 [00:15<00:14,  3.69s/it]\u001b[A\n",
      "\n",
      "Validating... (loss=10736.27822):  57%|| 4/7 [00:15<00:09,  3.00s/it]\u001b[A\n",
      "\n",
      "Validating... (loss=10763.08186):  57%|| 4/7 [00:17<00:09,  3.00s/it]\u001b[A\n",
      "\n",
      "Validating... (loss=10763.08186):  71%|| 5/7 [00:17<00:05,  2.57s/it]\u001b[A\n",
      "\n",
      "Validating... (loss=10652.23218):  71%|| 5/7 [00:19<00:05,  2.57s/it]\u001b[A\n",
      "\n",
      "Validating... (loss=10652.23218):  86%|| 6/7 [00:19<00:02,  2.34s/it]\u001b[A\n",
      "\n",
      "Validating... (loss=10570.17004):  86%|| 6/7 [00:21<00:02,  2.34s/it]\u001b[A\n",
      "\n",
      "Validating... (loss=10570.17004): 100%|| 7/7 [00:21<00:00,  2.20s/it]\u001b[A\n",
      "Validating... (loss=10570.17004): 100%|| 7/7 [00:41<00:00,  5.90s/it]\n",
      "08/18/2024 19:01:11 - INFO - __main__ - \n",
      "\n",
      "08/18/2024 19:01:11 - INFO - __main__ - Validation Results\n",
      "08/18/2024 19:01:11 - INFO - __main__ - Global Steps: 5\n",
      "08/18/2024 19:01:11 - INFO - __main__ - Valid Loss: 10698.75736\n",
      "08/18/2024 19:01:11 - INFO - __main__ - Valid Accuracy: 0.00000\n",
      "08/18/2024 19:01:13 - INFO - __main__ - Saved model checkpoint to [DIR: model_checkpoints]\n",
      "\n",
      "Training (5 / 5 Steps) (loss=11004.04004):   8%|| 4/50 [02:09<24:46, 32.31s/it]\n",
      "08/18/2024 19:01:33 - INFO - __main__ - Best Accuracy: \t0.000000\n",
      "08/18/2024 19:01:33 - INFO - __main__ - Best Loss (MSE): \t10698.757359\n",
      "08/18/2024 19:01:33 - INFO - __main__ - End Training!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the command to run the script with arguments\n",
    "command = [\n",
    "    \"python\", \"train.py\",\n",
    "    \"--name\", \"experiment_20240813\",\n",
    "    \"--dataset\", \"facemap\",\n",
    "    \"--model_type\", \"ViT-B_16\",\n",
    "    \"--pretrained_dir\", \"ViT-B_16.npz\",\n",
    "    \"--output_dir\", \"model_checkpoints\",  # Added missing comma here\n",
    "    \"--train_batch_size\", str(20),\n",
    "    \"--eval_batch_size\", str(20),\n",
    "    \"--eval_every\", str(5), \n",
    "    \"--num_steps\", str(5),\n",
    "]\n",
    "\n",
    "# Run the script\n",
    "result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "# Print the output and errors (if any)\n",
    "print(\"Output:\", result.stdout)\n",
    "print(\"Errors:\", result.stderr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
