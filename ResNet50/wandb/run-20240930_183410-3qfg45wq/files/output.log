Epoch [1/50], Batch [0/45], Loss: 10621.6738
Epoch [1/50], Batch [10/45], Loss: 7605.6113
Epoch [1/50], Batch [20/45], Loss: 5331.2085
Epoch [1/50], Batch [30/45], Loss: 3292.6650
Epoch [1/50], Batch [40/45], Loss: 1832.4305
Epoch [1/50], Average Training Loss: 5306.5324
Epoch [1/50], Average Validation Loss: 2832.4034
Epoch [2/50], Batch [0/45], Loss: 1347.7738
Epoch [2/50], Batch [10/45], Loss: 757.9152
Epoch [2/50], Batch [20/45], Loss: 419.0060
Epoch [2/50], Batch [30/45], Loss: 416.1939
Epoch [2/50], Batch [40/45], Loss: 145.5399
Epoch [2/50], Average Training Loss: 543.5485
Epoch [2/50], Average Validation Loss: 769.9167
Epoch [3/50], Batch [0/45], Loss: 180.9804
Epoch [3/50], Batch [10/45], Loss: 46.7302
Epoch [3/50], Batch [20/45], Loss: 38.7164
Epoch [3/50], Batch [30/45], Loss: 61.9746
Epoch [3/50], Batch [40/45], Loss: 46.0696
Epoch [3/50], Average Training Loss: 90.0982
Epoch [3/50], Average Validation Loss: 73.8235
Epoch [4/50], Batch [0/45], Loss: 283.8107
Epoch [4/50], Batch [10/45], Loss: 129.4842
Epoch [4/50], Batch [20/45], Loss: 25.3021
Epoch [4/50], Batch [30/45], Loss: 27.7514
Epoch [4/50], Batch [40/45], Loss: 30.9136
Epoch [4/50], Average Training Loss: 67.5617
Epoch [4/50], Average Validation Loss: 45.3540
Epoch [5/50], Batch [0/45], Loss: 36.4681
Epoch [5/50], Batch [10/45], Loss: 33.7606
Epoch [5/50], Batch [20/45], Loss: 34.8204
Epoch [5/50], Batch [30/45], Loss: 57.2455
Epoch [5/50], Batch [40/45], Loss: 74.2935
Epoch [5/50], Average Training Loss: 69.9071
Epoch [5/50], Average Validation Loss: 68.7817
Epoch [6/50], Batch [0/45], Loss: 23.2101
Epoch [6/50], Batch [10/45], Loss: 24.6139
Epoch [6/50], Batch [20/45], Loss: 21.6646
Epoch [6/50], Batch [30/45], Loss: 27.6142
Epoch [6/50], Batch [40/45], Loss: 26.5180
Epoch [6/50], Average Training Loss: 34.6377
Epoch [6/50], Average Validation Loss: 44.1474
Epoch [7/50], Batch [0/45], Loss: 32.8889
Epoch [7/50], Batch [10/45], Loss: 32.3975
Epoch [7/50], Batch [20/45], Loss: 26.2538
Epoch [7/50], Batch [30/45], Loss: 35.2628
Epoch [7/50], Batch [40/45], Loss: 385.0832
Epoch [7/50], Average Training Loss: 45.2286
Epoch [7/50], Average Validation Loss: 99.0041
Epoch [8/50], Batch [0/45], Loss: 40.7000
Epoch [8/50], Batch [10/45], Loss: 36.3184
Epoch [8/50], Batch [20/45], Loss: 18.5219
Epoch [8/50], Batch [30/45], Loss: 34.2909
Epoch [8/50], Batch [40/45], Loss: 22.6191
Epoch [8/50], Average Training Loss: 32.9891
Epoch [8/50], Average Validation Loss: 53.1376
Epoch [9/50], Batch [0/45], Loss: 35.6147
Epoch [9/50], Batch [10/45], Loss: 18.2026
Epoch [9/50], Batch [20/45], Loss: 17.1044
Epoch [9/50], Batch [30/45], Loss: 19.7915
Epoch [9/50], Batch [40/45], Loss: 40.7828
Epoch [9/50], Average Training Loss: 41.0109
Epoch [9/50], Average Validation Loss: 131.1053
Epoch [10/50], Batch [0/45], Loss: 36.8751
Epoch [10/50], Batch [10/45], Loss: 72.9052
Epoch [10/50], Batch [20/45], Loss: 27.6138
Epoch [10/50], Batch [30/45], Loss: 56.6772
Epoch [10/50], Batch [40/45], Loss: 21.8540
Epoch [10/50], Average Training Loss: 45.0947
Epoch [10/50], Average Validation Loss: 43.2282
Epoch [11/50], Batch [0/45], Loss: 23.8572
Epoch [11/50], Batch [10/45], Loss: 20.1709
Epoch [11/50], Batch [20/45], Loss: 16.8784
Epoch [11/50], Batch [30/45], Loss: 25.2527
Epoch [11/50], Batch [40/45], Loss: 27.6053
Epoch [11/50], Average Training Loss: 28.1771
Epoch [11/50], Average Validation Loss: 43.8899
Epoch [12/50], Batch [0/45], Loss: 20.8905
Epoch [12/50], Batch [10/45], Loss: 16.8648
Epoch [12/50], Batch [20/45], Loss: 25.0339
Epoch [12/50], Batch [30/45], Loss: 19.5211
Epoch [12/50], Batch [40/45], Loss: 22.9359
Epoch [12/50], Average Training Loss: 25.8574
Epoch [12/50], Average Validation Loss: 41.1771
Epoch [13/50], Batch [0/45], Loss: 25.3053
Epoch [13/50], Batch [10/45], Loss: 20.7425
Epoch [13/50], Batch [20/45], Loss: 38.6018
Epoch [13/50], Batch [30/45], Loss: 22.3431
Epoch [13/50], Batch [40/45], Loss: 19.1868
Epoch [13/50], Average Training Loss: 24.4840
Epoch [13/50], Average Validation Loss: 41.2464
Epoch [14/50], Batch [0/45], Loss: 26.4289
Epoch [14/50], Batch [10/45], Loss: 24.8244
Epoch [14/50], Batch [20/45], Loss: 26.9805
Epoch [14/50], Batch [30/45], Loss: 136.8924
Epoch [14/50], Batch [40/45], Loss: 67.6144
Epoch [14/50], Average Training Loss: 31.5403
Epoch [14/50], Average Validation Loss: 68.1824
Epoch [15/50], Batch [0/45], Loss: 21.5879
Epoch [15/50], Batch [10/45], Loss: 14.7682
Epoch [15/50], Batch [20/45], Loss: 23.5808
Epoch [15/50], Batch [30/45], Loss: 18.1599
Epoch [15/50], Batch [40/45], Loss: 25.6384
Epoch [15/50], Average Training Loss: 22.1143
Epoch [15/50], Average Validation Loss: 42.2649
Epoch [16/50], Batch [0/45], Loss: 32.7260
Epoch [16/50], Batch [10/45], Loss: 21.7012
Epoch [16/50], Batch [20/45], Loss: 25.0273
Epoch [16/50], Batch [30/45], Loss: 20.9675
Epoch [16/50], Batch [40/45], Loss: 20.9130
Epoch [16/50], Average Training Loss: 21.2624
Epoch [16/50], Average Validation Loss: 40.4173
Epoch [17/50], Batch [0/45], Loss: 22.5141
Epoch [17/50], Batch [10/45], Loss: 15.9935
Epoch [17/50], Batch [20/45], Loss: 18.9234
Epoch [17/50], Batch [30/45], Loss: 15.1370
Epoch [17/50], Batch [40/45], Loss: 18.3015
Epoch [17/50], Average Training Loss: 24.0488
Epoch [17/50], Average Validation Loss: 43.5294
Epoch [18/50], Batch [0/45], Loss: 20.5317
Epoch [18/50], Batch [10/45], Loss: 21.3435
Epoch [18/50], Batch [20/45], Loss: 29.7484
Epoch [18/50], Batch [30/45], Loss: 19.3981
Epoch [18/50], Batch [40/45], Loss: 22.7464
Epoch [18/50], Average Training Loss: 21.1303
Epoch [18/50], Average Validation Loss: 39.6649
Epoch [19/50], Batch [0/45], Loss: 18.5631
Epoch [19/50], Batch [10/45], Loss: 16.8470
Epoch [19/50], Batch [20/45], Loss: 19.1336
Epoch [19/50], Batch [30/45], Loss: 15.9581
Epoch [19/50], Batch [40/45], Loss: 18.4457
Epoch [19/50], Average Training Loss: 21.6989
Epoch [19/50], Average Validation Loss: 40.8015
Epoch [20/50], Batch [0/45], Loss: 29.1320
Epoch [20/50], Batch [10/45], Loss: 59.9857
Epoch [20/50], Batch [20/45], Loss: 33.9176
Epoch [20/50], Batch [30/45], Loss: 21.6844
Epoch [20/50], Batch [40/45], Loss: 26.4689
Epoch [20/50], Average Training Loss: 22.3046
Epoch [20/50], Average Validation Loss: 40.5330
Epoch [21/50], Batch [0/45], Loss: 23.6534
Epoch [21/50], Batch [10/45], Loss: 30.9321
Epoch [21/50], Batch [20/45], Loss: 13.9617
Epoch [21/50], Batch [30/45], Loss: 15.9532
Epoch [21/50], Batch [40/45], Loss: 20.7623
Epoch [21/50], Average Training Loss: 24.7949
Epoch [21/50], Average Validation Loss: 45.2675
Epoch [22/50], Batch [0/45], Loss: 15.6991
Epoch [22/50], Batch [10/45], Loss: 19.7399
Epoch [22/50], Batch [20/45], Loss: 25.2938
Epoch [22/50], Batch [30/45], Loss: 18.2403
Epoch [22/50], Batch [40/45], Loss: 17.2751
Epoch [22/50], Average Training Loss: 20.9909
Epoch [22/50], Average Validation Loss: 39.6984
Epoch [23/50], Batch [0/45], Loss: 20.5765
Epoch [23/50], Batch [10/45], Loss: 25.0224
Epoch [23/50], Batch [20/45], Loss: 21.3203
Epoch [23/50], Batch [30/45], Loss: 18.4380
Epoch [23/50], Batch [40/45], Loss: 18.9162
Epoch [23/50], Average Training Loss: 24.8916
Epoch [23/50], Average Validation Loss: 40.1309
Epoch [24/50], Batch [0/45], Loss: 19.3919
Epoch [24/50], Batch [10/45], Loss: 15.1625
Epoch [24/50], Batch [20/45], Loss: 13.3368
Epoch [24/50], Batch [30/45], Loss: 16.8280
Epoch [24/50], Batch [40/45], Loss: 18.9046
Epoch [24/50], Average Training Loss: 20.2849
Epoch [24/50], Average Validation Loss: 39.4507
Epoch [25/50], Batch [0/45], Loss: 18.0811
Epoch [25/50], Batch [10/45], Loss: 15.6772
Epoch [25/50], Batch [20/45], Loss: 22.6738
Epoch [25/50], Batch [30/45], Loss: 18.4919
Epoch [25/50], Batch [40/45], Loss: 20.6848
Epoch [25/50], Average Training Loss: 21.3441
Epoch [25/50], Average Validation Loss: 41.0799
Epoch [26/50], Batch [0/45], Loss: 22.6987
Epoch [26/50], Batch [10/45], Loss: 29.0572
Epoch [26/50], Batch [20/45], Loss: 16.2587
Epoch [26/50], Batch [30/45], Loss: 21.9118
Epoch [26/50], Batch [40/45], Loss: 15.7488
Epoch [26/50], Average Training Loss: 19.9185
Epoch [26/50], Average Validation Loss: 39.3745
Epoch [27/50], Batch [0/45], Loss: 19.2793
Epoch [27/50], Batch [10/45], Loss: 19.2884
Epoch [27/50], Batch [20/45], Loss: 17.5229
Epoch [27/50], Batch [30/45], Loss: 14.0289
Epoch [27/50], Batch [40/45], Loss: 15.8413
Epoch [27/50], Average Training Loss: 22.8444
Epoch [27/50], Average Validation Loss: 40.7532
Epoch [28/50], Batch [0/45], Loss: 19.0626
Epoch [28/50], Batch [10/45], Loss: 30.8011
Epoch [28/50], Batch [20/45], Loss: 19.4441
Epoch [28/50], Batch [30/45], Loss: 20.4817
Epoch [28/50], Batch [40/45], Loss: 19.9276
Epoch [28/50], Average Training Loss: 22.5390
Epoch [28/50], Average Validation Loss: 40.7608
Epoch [29/50], Batch [0/45], Loss: 19.8732
Epoch [29/50], Batch [10/45], Loss: 24.0567
Epoch [29/50], Batch [20/45], Loss: 21.5809
Epoch [29/50], Batch [30/45], Loss: 24.2534
Epoch [29/50], Batch [40/45], Loss: 17.2994
Epoch [29/50], Average Training Loss: 22.9967
Epoch [29/50], Average Validation Loss: 41.8273
Epoch [30/50], Batch [0/45], Loss: 18.8277
Epoch [30/50], Batch [10/45], Loss: 27.0654
Epoch [30/50], Batch [20/45], Loss: 50.7048
Epoch [30/50], Batch [30/45], Loss: 19.6264
Epoch [30/50], Batch [40/45], Loss: 15.6522
Epoch [30/50], Average Training Loss: 22.9765
Epoch [30/50], Average Validation Loss: 40.4579
Epoch [31/50], Batch [0/45], Loss: 21.9236
Epoch [31/50], Batch [10/45], Loss: 28.8821
Epoch [31/50], Batch [20/45], Loss: 27.7509
Epoch [31/50], Batch [30/45], Loss: 16.7019
Epoch [31/50], Batch [40/45], Loss: 47.8046
Epoch [31/50], Average Training Loss: 20.9896
Epoch [31/50], Average Validation Loss: 41.1776
Epoch [32/50], Batch [0/45], Loss: 21.5668
Epoch [32/50], Batch [10/45], Loss: 23.9545
Epoch [32/50], Batch [20/45], Loss: 20.7900
Epoch [32/50], Batch [30/45], Loss: 16.4059
Epoch [32/50], Batch [40/45], Loss: 20.4116
Epoch [32/50], Average Training Loss: 21.4581
Epoch [32/50], Average Validation Loss: 42.9495
Epoch [33/50], Batch [0/45], Loss: 27.4353
Epoch [33/50], Batch [10/45], Loss: 20.3801
Epoch [33/50], Batch [20/45], Loss: 32.8057
Epoch [33/50], Batch [30/45], Loss: 23.3826
Epoch [33/50], Batch [40/45], Loss: 15.6076
Epoch [33/50], Average Training Loss: 20.9602
Epoch [33/50], Average Validation Loss: 40.5613
Epoch [34/50], Batch [0/45], Loss: 34.4137
Epoch [34/50], Batch [10/45], Loss: 20.2840
Epoch [34/50], Batch [20/45], Loss: 25.1663
Epoch [34/50], Batch [30/45], Loss: 16.4708
Epoch [34/50], Batch [40/45], Loss: 24.5286
Epoch [34/50], Average Training Loss: 20.9233
Epoch [34/50], Average Validation Loss: 39.4953
Epoch [35/50], Batch [0/45], Loss: 13.7942
Epoch [35/50], Batch [10/45], Loss: 20.4821
Epoch [35/50], Batch [20/45], Loss: 13.4512
Epoch [35/50], Batch [30/45], Loss: 16.4403
Epoch [35/50], Batch [40/45], Loss: 18.5019
Epoch [35/50], Average Training Loss: 21.5760
Epoch [35/50], Average Validation Loss: 41.5053
Epoch [36/50], Batch [0/45], Loss: 17.5307
Epoch [36/50], Batch [10/45], Loss: 20.7094
Epoch [36/50], Batch [20/45], Loss: 19.9304
Epoch [36/50], Batch [30/45], Loss: 61.3648
Epoch [36/50], Batch [40/45], Loss: 20.8214
Epoch [36/50], Average Training Loss: 21.2076
Epoch [36/50], Average Validation Loss: 40.3835
Epoch [37/50], Batch [0/45], Loss: 23.6608
Epoch [37/50], Batch [10/45], Loss: 18.9807
Epoch [37/50], Batch [20/45], Loss: 17.1078
Epoch [37/50], Batch [30/45], Loss: 15.1218
Epoch [37/50], Batch [40/45], Loss: 19.7253
Epoch [37/50], Average Training Loss: 21.3974
Epoch [37/50], Average Validation Loss: 41.7120
Epoch [38/50], Batch [0/45], Loss: 20.7307
Epoch [38/50], Batch [10/45], Loss: 25.3423
Epoch [38/50], Batch [20/45], Loss: 26.4484
Epoch [38/50], Batch [30/45], Loss: 23.2638
Epoch [38/50], Batch [40/45], Loss: 19.9157
Epoch [38/50], Average Training Loss: 21.2403
Epoch [38/50], Average Validation Loss: 40.3583
Epoch [39/50], Batch [0/45], Loss: 18.4902
Epoch [39/50], Batch [10/45], Loss: 17.0130
Epoch [39/50], Batch [20/45], Loss: 19.4421
Epoch [39/50], Batch [30/45], Loss: 19.8794
Epoch [39/50], Batch [40/45], Loss: 19.5498
Epoch [39/50], Average Training Loss: 21.0536
Epoch [39/50], Average Validation Loss: 41.0159
Epoch [40/50], Batch [0/45], Loss: 53.0463
Epoch [40/50], Batch [10/45], Loss: 18.1961
Epoch [40/50], Batch [20/45], Loss: 19.5514
Epoch [40/50], Batch [30/45], Loss: 22.2648
Epoch [40/50], Batch [40/45], Loss: 16.6745
Epoch [40/50], Average Training Loss: 23.9189
Epoch [40/50], Average Validation Loss: 40.4586
Epoch [41/50], Batch [0/45], Loss: 21.1235
Epoch [41/50], Batch [10/45], Loss: 13.9616
Epoch [41/50], Batch [20/45], Loss: 27.5001
Epoch [41/50], Batch [30/45], Loss: 20.8093
Epoch [41/50], Batch [40/45], Loss: 28.7311
Epoch [41/50], Average Training Loss: 22.0826
Epoch [41/50], Average Validation Loss: 43.3254
Epoch [42/50], Batch [0/45], Loss: 21.5976
Epoch [42/50], Batch [10/45], Loss: 18.0893
Epoch [42/50], Batch [20/45], Loss: 18.6054
Epoch [42/50], Batch [30/45], Loss: 26.4982
Epoch [42/50], Batch [40/45], Loss: 20.4138
Epoch [42/50], Average Training Loss: 22.1371
Epoch [42/50], Average Validation Loss: 43.6188
Epoch [43/50], Batch [0/45], Loss: 16.2017
Epoch [43/50], Batch [10/45], Loss: 21.3547
Epoch [43/50], Batch [20/45], Loss: 28.6332
Epoch [43/50], Batch [30/45], Loss: 24.9313
Epoch [43/50], Batch [40/45], Loss: 20.4790
Epoch [43/50], Average Training Loss: 22.8733
Epoch [43/50], Average Validation Loss: 43.0968
Epoch [44/50], Batch [0/45], Loss: 15.9941
Epoch [44/50], Batch [10/45], Loss: 21.5727
Epoch [44/50], Batch [20/45], Loss: 53.1956
Epoch [44/50], Batch [30/45], Loss: 30.7221
Epoch [44/50], Batch [40/45], Loss: 21.2608
Epoch [44/50], Average Training Loss: 21.1300
Epoch [44/50], Average Validation Loss: 41.1622
Epoch [45/50], Batch [0/45], Loss: 16.9613
Epoch [45/50], Batch [10/45], Loss: 30.2591
Epoch [45/50], Batch [20/45], Loss: 18.8501
Epoch [45/50], Batch [30/45], Loss: 22.1392
Epoch [45/50], Batch [40/45], Loss: 18.5997
Epoch [45/50], Average Training Loss: 19.8414
Epoch [45/50], Average Validation Loss: 39.4550
Epoch [46/50], Batch [0/45], Loss: 21.1954
Epoch [46/50], Batch [10/45], Loss: 17.4985
Epoch [46/50], Batch [20/45], Loss: 19.0623
Epoch [46/50], Batch [30/45], Loss: 16.1956
Epoch [46/50], Batch [40/45], Loss: 18.9670
Epoch [46/50], Average Training Loss: 22.3153
Epoch [46/50], Average Validation Loss: 41.9573
Epoch [47/50], Batch [0/45], Loss: 17.7108
Epoch [47/50], Batch [10/45], Loss: 19.3670
Epoch [47/50], Batch [20/45], Loss: 25.5078
Epoch [47/50], Batch [30/45], Loss: 14.9003
Epoch [47/50], Batch [40/45], Loss: 13.3878
Epoch [47/50], Average Training Loss: 22.7949
Epoch [47/50], Average Validation Loss: 41.0025
Epoch [48/50], Batch [0/45], Loss: 23.7616
Epoch [48/50], Batch [10/45], Loss: 21.7209
Epoch [48/50], Batch [20/45], Loss: 25.2774
Epoch [48/50], Batch [30/45], Loss: 23.9989
Epoch [48/50], Batch [40/45], Loss: 22.4123
Epoch [48/50], Average Training Loss: 20.9459
Epoch [48/50], Average Validation Loss: 39.9863
Epoch [49/50], Batch [0/45], Loss: 17.1252
Epoch [49/50], Batch [10/45], Loss: 19.1645
Epoch [49/50], Batch [20/45], Loss: 17.0335
Epoch [49/50], Batch [30/45], Loss: 18.9577
Epoch [49/50], Batch [40/45], Loss: 62.2929
Epoch [49/50], Average Training Loss: 23.0005
Epoch [49/50], Average Validation Loss: 42.6742
Epoch [50/50], Batch [0/45], Loss: 19.0681
Epoch [50/50], Batch [10/45], Loss: 26.7642
Epoch [50/50], Batch [20/45], Loss: 17.4739
Epoch [50/50], Batch [30/45], Loss: 19.1731
Epoch [50/50], Batch [40/45], Loss: 16.3862
Epoch [50/50], Average Training Loss: 24.6993
Epoch [50/50], Average Validation Loss: 40.5640
C:\Users\avs20\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
C:\Users\avs20\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
